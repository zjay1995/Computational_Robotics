{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Setup\n",
    "Set up the systerm with state detection, actions transition probability calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class myStates:\n",
    "    def __init__(self,Length,Width):\n",
    "        print(\"new state created with size %d X %d...\" % (Length,Width))\n",
    "        self.L = Length\n",
    "        self.W = Width\n",
    "        if self.L <= 0 or self.W <= 0:\n",
    "            raise Exception('Dimension of state should be positive integers')\n",
    "        \n",
    "        self.stateMatrix = []\n",
    "        # Create state list\n",
    "        dir_mat = np.array(range(12))\n",
    "        for i in range(self.L):\n",
    "            for j in range(self.W):\n",
    "                for k in dir_mat:\n",
    "                    self.stateMatrix.append((i,j,k))\n",
    "        \n",
    "# Creating Actions\n",
    "class myActions:\n",
    "    def __init__(self,act = None,turn = None):\n",
    "        self.actionMat = (act,turn)\n",
    "        self.Set = {}\n",
    "        self.Set[0] = (0,0)\n",
    "        self.Set[1] = (1,0)\n",
    "        self.Set[2] = (1,1)\n",
    "        self.Set[3] = (1,-1)\n",
    "        self.Set[4] = (-1,0)\n",
    "        self.Set[5] = (-1,1) \n",
    "        self.Set[6] = (-1,-1)\n",
    "        # 0: (0,0): Stay still\n",
    "        # 1: (1,0): Forward only\n",
    "        # 2: (1,1): Forward clockwise\n",
    "        # 3: (1,-1): Forward counter-clockwise\n",
    "        # 4: (-1,0): Backward only\n",
    "        # 5: (-1,1): Backward clockwise\n",
    "        # 6: (-1,-1): Backward counter-clockwise\n",
    "        print('action done...')\n",
    "        \n",
    "# Creating Probability Space functions\n",
    "def transitionProbability(pe,s,a,s_next,myStates):\n",
    "    \n",
    "    L = myStates.L\n",
    "    W = myStates.W\n",
    "    # this function takes error probability pe, current state s = (x,y,h), future\n",
    "    # state s_next = (x',y',h') and size of states (L,W) as inputs, returns the transition \n",
    "    # probability between each state\n",
    "    \n",
    "    # pe threshold\n",
    "    if pe > 0.5 or pe < 0.0:\n",
    "        raise Exception('Error probability should lie between 0 and 0.5')\n",
    "    \n",
    "    # define possible cartesian movement\n",
    "    pos_x = [1,0]\n",
    "    pos_y = [0,1]\n",
    "    neg_x = [-1,0]\n",
    "    neg_y = [0,-1]\n",
    "    \n",
    "    # create a dictionary for possible heading direction based on current heading,\n",
    "    # consisting of three possible heading configuration for next state\n",
    "    \n",
    "    # h_dic[h] = [(moving_direction,h',possibility),~,~]\n",
    "    h_dic = {}\n",
    "    \n",
    "    h_dic[0] = [(pos_y,0,1-2*pe),(pos_y,1,pe),(pos_x,11,pe)]\n",
    "    h_dic[1] = [(pos_y,1,1-2*pe),(pos_x,2,pe),(pos_x,0,pe)]\n",
    "    h_dic[2] = [(pos_x,2,1-2*pe),(pos_x,3,pe),(pos_x,1,pe)]\n",
    "    h_dic[3] = [(pos_x,3,1-2*pe),(pos_x,4,pe),(neg_y,2,pe)]\n",
    "    h_dic[4] = [(pos_x,4,1-2*pe),(neg_y,5,pe),(neg_y,3,pe)]\n",
    "    h_dic[5] = [(neg_y,5,1-2*pe),(neg_y,6,pe),(neg_y,4,pe)]\n",
    "    h_dic[6] = [(neg_y,6,1-2*pe),(neg_y,7,pe),(neg_x,5,pe)]\n",
    "    h_dic[7] = [(neg_y,7,1-2*pe),(neg_x,8,pe),(neg_x,6,pe)]\n",
    "    h_dic[8] = [(neg_x,8,1-2*pe),(neg_x,9,pe),(neg_x,7,pe)]\n",
    "    h_dic[9] = [(neg_x,9,1-2*pe),(neg_x,10,pe),(pos_y,8,pe)]\n",
    "    h_dic[10] = [(neg_x,10,1-2*pe),(pos_y,11,pe),(pos_y,9,pe)]\n",
    "    h_dic[11] = [(pos_y,11,1-2*pe),(pos_y,0,pe),(pos_y,10,pe)]\n",
    "    \n",
    "    \n",
    "    # create a dictionary for transition probability based on future state \n",
    "    # and current state\n",
    "    transProb = {}\n",
    "\n",
    "    for map_key in h_dic[s[2]]:\n",
    "        x_new = s[0] + a[0]*map_key[0][0]   # move in x direction, a[0] indicates forward or backward\n",
    "        xd = x_new if (x_new <= L-1 and x_new >= 0) else s[0]       # else for off-grid movement\n",
    "        y_new = s[1] + a[0]*map_key[0][1]   # move in y direction, a[0] indicates forward or backward\n",
    "        yd = y_new if (y_new <= W-1 and y_new >= 0) else s[1]       # else for off-grid movement\n",
    "        hd = (map_key[1] + a[1]) % 12       # new heading direction\n",
    "        if a[0] == 0 and a[1] == 0:\n",
    "            transProb[s] = 1\n",
    "        else: transProb[(xd,yd,hd)] = map_key[2]\n",
    "    \n",
    "    # match with the keys in transProb dictionary\n",
    "    if s_next in transProb.keys():\n",
    "       # print(\"p = %f\" %(transProb[s_next]))\n",
    "        return(transProb[s_next]);\n",
    "    else: \n",
    "       # print(\"p = 0\")\n",
    "        return 0.0\n",
    "    \n",
    "        \n",
    "\n",
    "# update state based on action and current state\n",
    "def stateUpdate(pe,s,a,myStates):\n",
    "    \n",
    "    S = myStates.stateMatrix\n",
    "    P = []\n",
    "    # search for probability trasferring to state s_next given current state and action\n",
    "    for s_next in S:\n",
    "        pt = transitionProbability(pe,s,a,s_next,myStates)\n",
    "        if pt != 0:\n",
    "            P.append((s_next,pt))\n",
    "    \n",
    "    prob = np.array([])\n",
    "    for p in P:\n",
    "        prob = np.append(prob,p[1])\n",
    "\n",
    "    # return a choice given discrete pdf\n",
    "    state_id = np.random.choice(np.arange(len(P)),p=prob)\n",
    "    s_next = P[state_id][0]\n",
    "    return(s_next)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reward map for state input\n",
    "def rewardFun(s,myStates):\n",
    "    \n",
    "    # Extract information from states\n",
    "    S = myStates.stateMatrix\n",
    "    L = myStates.L\n",
    "    W = myStates.W\n",
    "    \n",
    "    \n",
    "    x_pos = s[0]\n",
    "    y_pos = s[1]\n",
    "    h = s[2]\n",
    "    \n",
    "    if x_pos < 0 or x_pos >= L or y_pos < 0 or y_pos >= W or h < 0 or h >= 12:\n",
    "        raise Exception('Invalid state definition: [x,y,h] should be within range')\n",
    "    \n",
    "    pos = [x_pos,y_pos]\n",
    "    \n",
    "    if x_pos == 0 or y_pos == 0 or x_pos == (L-1) or y_pos == (W-1):\n",
    "        r = -100\n",
    "    elif pos == [2,2] or pos == [2,3] or pos == [2,4] or pos == [4,2] or pos == [4,3] or pos == [4,4]:\n",
    "        r = -1\n",
    "    elif pos == [3,4]:\n",
    "        r = 1\n",
    "    else: r = 0\n",
    "     \n",
    "    # print(\"reward for state (%d,%d,%d) is %d\" %(s[0],s[1],s[2],r))\n",
    "    return r\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValueIteration(pe,myStates,myActions,gamma,epsilon=0.5):\n",
    "    \n",
    "    # this function takes error probability, action, current state,\n",
    "    # next state, state map and time discount as input and returns the optimal \n",
    "    # policy for each state as well as value for each state\n",
    "    \n",
    "    \"\"\"\n",
    "    input: pe = error_probability, myStates = list(all possible states), myAction = list(all actions)\n",
    "            gamma = time_discount, epsilon = convergence threshold\n",
    "    return: list(policy,value)\n",
    "    \n",
    "    NOTE: 1.This function runs slowly as not optimized for efficiency, please be patient\n",
    "          2. epsilon is usually set to be 0.01 and default value 0.5 used for demo\n",
    "    \"\"\"\n",
    "    \n",
    "    start = timer()\n",
    "    if epsilon > 0.5 or epsilon < 0.0:\n",
    "        raise Exception(\"Invalid epsilon. Enter a value between 0 and 0.5\")\n",
    "        \n",
    "        \n",
    "    S = myStates.stateMatrix\n",
    "    A = myActions.Set\n",
    "    # initializae all states' values\n",
    "    V = {}\n",
    "    for s in S:\n",
    "        V[s] = 0\n",
    "    \n",
    "    pi = {}\n",
    "    max_value = {}\n",
    "        \n",
    "        \n",
    "    # set a large threshold bigger than epsilon to enter in the loop\n",
    "    delta = 10000\n",
    "    \n",
    "    # perform value iteration\n",
    "    while delta > epsilon:\n",
    "        \n",
    "        # initialize delta to be zero, construct empty list for policy and value\n",
    "        delta = 0\n",
    "        policy = []\n",
    "        value = []\n",
    "        \n",
    "        # iteration for agent being at state s in S\n",
    "        for s in S:\n",
    "            v = np.copy(V[s])\n",
    "            value_action = []\n",
    "            \n",
    "            # for all actions, find value for action a at state s, sum over all future state s2\n",
    "            for a in range(0,7):\n",
    "                value_action.append(sum(transitionProbability(pe,s,A[a],s2,myStates)*(rewardFun(s2,myStates)+gamma*V[s2]) for s2 in S))\n",
    "            V[s] = max(value_action)\n",
    "            pi[s] = np.argmax(value_action)\n",
    "            \n",
    "            # construct policy list and value list\n",
    "            policy.append(pi[s])\n",
    "            value.append(V[s])\n",
    "            \n",
    "            # update delta for each state\n",
    "            delta = max(delta,abs(v-V[s]))\n",
    "    \n",
    "    end = timer()\n",
    "    \n",
    "    print(\"Value iteration costs %f seconds.......\" %(end - start))\n",
    "\n",
    "    return(policy,value)\n",
    "\n",
    "\n",
    "def mappingState(policy,value,myStates,myActions):\n",
    "    A = myActions.Set\n",
    "    S = myStates.stateMatrix\n",
    "    \n",
    "    # convert input list to array\n",
    "    V = np.asarray(value)\n",
    "    P = np.asarray(policy)\n",
    "    \n",
    "    vmap = {}\n",
    "    pmap = {}\n",
    "    \n",
    "    \n",
    "    # mapping state with policy and value\n",
    "    ct = 0\n",
    "    for s in S:\n",
    "        vmap[s] = V[ct]\n",
    "        pmap[s] = A[P[ct]]\n",
    "        ct = ct + 1\n",
    "        \n",
    "    return(vmap,pmap)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new state created with size 4 X 3...\n",
      "new state created with size 2 X 7...\n",
      "new state created with size 1 X 1...\n",
      "new state created with size 6 X 6...\n",
      "action done...\n",
      "Value iteration costs 65.431251 seconds.......\n"
     ]
    }
   ],
   "source": [
    "# testing & debugging: \n",
    "S = myStates(4,3)\n",
    "S = myStates(2,7)\n",
    "S = myStates(1,1)\n",
    "S = myStates(6,6)\n",
    "A = myActions()\n",
    "\n",
    "\n",
    "\n",
    "p = transitionProbability(0.2,(0,0,0),(0,0),(0,0,1),S)\n",
    "\n",
    "s_next = stateUpdate(0.2,(4,1,1),(1,1),S)\n",
    "\n",
    "r = rewardFun((0,0,0),S)\n",
    "\n",
    "policy,value = ValueIteration(0.2,S,A,0.9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 3, 2, 2, 6, 5, 5, 6, 5, 5, 3, 2, 2, 1, 3, 2, 6, 5, 5, 4, 6, 5, 3, 2, 2, 3, 1, 3, 6, 5, 5, 6, 4, 6, 3, 2, 2, 3, 1, 3, 6, 5, 5, 6, 4, 6, 3, 5, 5, 2, 1, 3, 3, 2, 2, 5, 4, 6, 6, 5, 5, 3, 2, 2, 3, 2, 2, 6, 5, 5, 6, 1, 3, 3, 2, 2, 5, 4, 6, 6, 5, 5, 2, 3, 1, 1, 0, 0, 5, 6, 4, 4, 0, 0, 2, 2, 1, 2, 1, 1, 4, 5, 4, 5, 4, 4, 1, 3, 2, 1, 3, 1, 6, 6, 5, 4, 6, 4, 3, 0, 0, 2, 3, 3, 1, 0, 0, 5, 6, 6, 4, 6, 5, 3, 2, 2, 3, 3, 2, 6, 5, 5, 6, 1, 3, 6, 5, 5, 5, 4, 6, 3, 2, 2, 2, 1, 3, 3, 6, 5, 6, 4, 6, 6, 3, 2, 3, 2, 1, 3, 2, 2, 6, 5, 4, 6, 5, 5, 3, 2, 2, 3, 2, 2, 6, 5, 5, 6, 5, 5, 3, 5, 4, 1, 3, 3, 3, 2, 1, 4, 6, 6, 6, 4, 6, 3, 2, 2, 3, 1, 3, 6, 5, 5, 6, 1, 3, 6, 5, 5, 5, 4, 6, 3, 2, 2, 2, 3, 3, 4, 6, 5, 4, 6, 6, 1, 3, 2, 1, 3, 3, 2, 6, 4, 4, 6, 6, 5, 3, 1, 1, 3, 2, 4, 5, 4, 4, 6, 5, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 6, 3, 2, 2, 1, 1, 3, 6, 5, 5, 4, 3, 2, 6, 5, 5, 6, 6, 5, 3, 2, 2, 3, 0, 0, 6, 5, 5, 6, 0, 0, 3, 2, 2, 3, 5, 5, 6, 5, 5, 3, 2, 2, 3, 2, 2, 6, 5, 6, 6, 4, 5, 3, 2, 3, 3, 1, 2, 6, 5, 5, 4, 0, 0, 3, 2, 2, 1, 0, 0, 6, 4, 6, 6, 5, 5, 2, 1, 3, 3, 2, 2, 5, 2, 2, 6, 5, 5, 6, 5, 5, 3, 2, 2, 3, 2, 2, 5, 4, 6, 6, 5, 5, 2, 1, 3, 3, 5, 5, 5, 4, 6, 3, 2, 2, 2, 1, 3, 6, 5, 5, 4, 4, 6, 3, 2, 2, 1, 1, 3, 6, 5, 5, 6, 6, 5, 3, 2, 2, 3, 3, 2, 6, 5, 5, 6, 5, 5, 3, 2, 2, 3, 2, 2, 6]\n",
      "[-135.9552276126714, -137.79132051514785, -158.6711611996527, -205.13785458219314, -151.77393909482134, -186.89944679614098, -135.9552276126714, -137.79132051514785, -158.6711611996527, -205.1341874864135, -151.7683276500447, -186.89932877068247, -112.28629690654722, -59.94696173318082, 0.2595012021282899, -44.569224871423984, -91.68294805728812, -162.7541279839562, -112.28629690654722, -59.94696173318082, 0.2595012021282899, -44.569224871423984, -91.68193799722832, -162.7541074334725, -111.69878353365623, -59.592800155109444, 0.331370125866708, -19.917467965533728, -56.455075566226256, -159.03234348206146, -111.69878353365623, -59.592800155109444, 0.331370125866708, -19.917467965533728, -56.4548937554155, -159.03234047707323, -147.50325518172414, -58.66607507558997, 0.9874712686633321, -19.478910885359447, -49.765433163757656, -157.71615791018266, -147.50325518172414, -58.66607507558997, 0.9874712686633321, -19.478910885359447, -49.765400437811714, -157.71615652371815, -160.4454541226086, -125.42910823027822, 2.235543573111139, -18.04442239033528, -47.324558838397806, -158.7684462916267, -160.4454541226086, -125.42910823027822, 2.235543573111139, -18.04442239033528, -47.32455294772753, -158.76842837005228, -204.12786114109173, -150.20726339384203, -185.76764763768222, -134.7354803408311, -136.52927011335734, -157.38157813548798, -204.12786114109173, -150.20726339384203, -185.76764764681434, -134.7354803408311, -136.5292690530367, -157.38157172864263, -19.864859108605557, -48.856878201609376, -159.0192329625201, -161.4475377123381, -126.33197574342185, 0.17069098090645285, -19.864859108605557, -48.856878201609376, -159.0192329625201, -161.4475377123381, -126.31394365498788, 0.17069098090645285, 0.41941970111809657, 0.4523778633602594, 0.6928289174798794, 0.0, 0.0, 0.4734540939243112, 0.4194197011180966, 0.4523778633602594, 0.6928289174798794, 0.0, 0.0, 0.4734540939243112, 0.922465168802874, 0.8297828660363653, 0.1924111486692569, 0.27555864395869945, 0.4255715067535452, 0.8757830228888375, 0.922465168802874, 0.8297828660363653, 0.1924111486692569, 0.27555864395869945, 0.4255715067535452, 0.8757830228888375, 0.7532717104919036, 1.8551376528982393, 1.146499146084402, 1.007532303998788, 1.0482881344283506, 1.609874480784819, 0.7532717104919036, 1.8551376528982393, 1.146499146084402, 1.007532303998788, 1.0482881344283506, 1.609874480784819, 0.0, 0.0, 3.0022917394849316, 3.1542729779566723, 2.204516091797262, 1.193612991709448, 0.0, 0.0, 3.0022917394849316, 3.1542729779566723, 2.204516091797262, 1.1936129917094482, -43.93071741402351, -89.6684563329193, -161.89155663393606, -109.71467950881218, -58.54231996416346, 1.9730581641104232, -43.93071760488123, -89.6684563329193, -161.89155663393606, -109.71467950881218, -58.54231996416346, 1.9730581641104232, -19.574083160786863, -49.604829982847875, -158.5818508016717, -148.15908974705656, -59.86743622660871, 0.13713713548657297, -19.574083160786863, -49.604829982847875, -158.5818508016717, -148.1493524193022, -59.86743622660871, 0.13713713548657297, 0.5062428064197172, 0.7807561594178339, 1.3748040714274241, 0.3731635931713539, 0.3940514892298574, 0.278559678598796, 0.5062428064197172, 0.780756159417834, 1.3748040714274241, 0.3731635931713539, 0.3940514892298574, 0.278559678598796, 1.6802619667892709, 1.4933980173485317, 1.6664880187088391, 1.5121186368374824, 2.135606867047848, 1.1116776751707587, 1.6802619667892709, 1.4933980173485317, 1.666488018708839, 1.5121186368374824, 2.135606867047848, 1.1116776751707587, 1.6192145781918836, 3.16021937078483, 2.742172509293974, 2.592290813204476, 3.1040531300906817, 1.9645687765056192, 1.6192145781918836, 3.16021937078483, 2.742172509293974, 2.592290813204476, 3.1040531300906817, 1.9645687765056192, 1.4001095118967237, 1.646930973331096, 5.6953279000000006, 4.92510180674127, 4.069517355089238, 1.4964234163967853, 1.4001095118967237, 1.646930973331096, 5.6953279000000006, 4.92510180674127, 4.069517355089238, 1.4964234163967853, -19.392342818836298, -55.629112533961376, -155.99321550255806, -109.39265278449946, -56.33999009794253, 2.353413911913039, -19.392342818836298, -55.629112533961376, -155.99321550255806, -109.39265278449946, -56.33999009794253, 2.353413911913039, -18.32820978539424, -54.9922877968952, -158.8546763039804, -112.14173161230703, -59.37117888656854, 1.9915938077796682, -18.32820978539424, -54.9922877968952, -158.8546763039804, -112.14173161230703, -59.37117888656854, 1.9915938077796682, 2.803439592568857, 1.8162981966321459, 0.9500997540368629, 1.155588070433915, 1.0065689271559353, 2.8297005945435103, 2.803439592568857, 1.8162981966321459, 0.9500997540368629, 1.155588070433915, 1.0065689271559353, 2.82970059454351, 3.7372126176531366, 2.2751867080843575, 0.5118824623976822, 0.9620543714991661, 1.8453464322250217, 4.110105568893087, 3.7372126176531366, 2.2751867080843575, 0.5118824623976821, 0.962054371499166, 1.8453464322250217, 4.110105568893086, 4.6809001181346614, 3.684735246540772, 1.516224988136821, 2.36887665001998, 3.3543198502489684, 5.6953279000000006, 4.6809001181346614, 3.684735246540772, 1.516224988136821, 2.36887665001998, 3.3543198502489684, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, 5.6953279000000006, -14.675749407855655, -45.9141486859687, -156.79219517272037, -144.7719371211593, -57.274961209948714, 6.12579511, -14.675749407855655, -45.9141486859687, -156.79219517272037, -144.73280433214785, -57.274961209948714, 6.12579511, -44.64494707672761, -90.83054937617956, -161.58875490641083, -111.55268002470198, -58.688434381732634, 0.8925405614611137, -44.644723534586454, -90.83054937617956, -161.58875490641083, -111.55268002470198, -58.688434381732634, 0.8925405614611137, 0.0, 0.0, 1.6564381085703885, 1.1388243090416363, 1.6335841805199227, 0.508953307276479, 0.0, 0.0, 1.6564381085703885, 1.1388243090416361, 1.6335841805199225, 0.508953307276479, 0.9708571307202346, 1.477179972953044, 1.9934379367747004, 1.9548492106870505, 2.3090472450439736, 1.1787354284180191, 0.9708571307202346, 1.477179972953044, 1.9934379367747004, 1.9548492106870503, 2.3090472450439736, 1.178735428418019, 1.1990580352783289, 1.612674216966266, 3.1052395522608838, 2.708129986055604, 2.0207471803953583, 0.8109307473626585, 1.1990580352783289, 1.612674216966266, 3.1052395522608838, 2.708129986055604, 2.0207471803953583, 0.8109307473626585, 1.854946218568743, 3.5271474022208773, 6.12579511, -5.6953279000000006, -5.6953279000000006, 0.7246344094287807, 1.854946218568743, 3.5271474022208773, 6.12579511, -5.6953279000000006, -5.6953279000000006, 0.7246344094287807, -18.06079938977312, -46.76023268564725, -155.65787031492678, -158.3930900040006, -122.0252088169187, 0.7669916841240597, -18.06079938977312, -46.76023268564725, -155.65787031492678, -158.3930900040006, -121.95952684281414, 0.7669916841240597, -204.8850073191315, -151.06999904388738, -186.1705630201019, -135.00203026057227, -137.27268755214487, -158.30631751089513, -204.8850073191315, -151.06999904388738, -186.17052278251649, -135.00203026057227, -137.2729036613356, -158.30785559155188, -161.00229752948997, -125.90645690926479, 1.2071691389187398, -18.99885087739235, -48.2339525403612, -158.81785702564093, -161.00229752948997, -125.90645690926479, 1.2071691389187396, -18.99885087739235, -48.234128061427754, -158.8186604433588, -147.79744200246796, -59.13036341192866, 0.8300659064983686, -19.122056823040364, -49.355494359860394, -158.05334179434107, -147.79744200246796, -59.13036341192866, 0.8300659064983685, -19.122056823040364, -49.355437462778724, -158.0535811909062, -111.76515393292168, -59.17401965394694, 1.454574114764814, -18.611120766687822, -55.34420884770063, -158.54353870545327, -111.76515393292168, -59.17401965394694, 1.454574114764814, -18.611120766687822, -55.342825672943746, -158.54355107241088, -111.5582569531313, -60.004802467627236, 2.3411930363416475, -42.98803802601677, -91.84361796638035, -161.77371148274375, -111.5582569531313, -60.004802467627236, 2.3411930363416475, -42.98803802601677, -91.83545726402085, -161.7729667944274, -135.23212247613637, -135.66335384451213, -156.5198861970955, -202.20524378590443, -151.22074503804492, -186.4526686134223, -135.23212247613637, -135.66335384451213, -156.5198861970955, -202.16101157076122, -151.17840110988143, -186.4481277902512]\n",
      "4.92510180674127\n",
      "(-1, -1)\n"
     ]
    }
   ],
   "source": [
    "vmap,pmap = mappingState(policy,value,S,A)\n",
    "\n",
    "print(policy)\n",
    "\n",
    "print(value)\n",
    "\n",
    "print(vmap[(2,4,3)])\n",
    "\n",
    "print(pmap[(2,4,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
